{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3VZEeejzwFzB/sxsBBCka",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/con321dude/Side-Projects/blob/master/DataWranglingPractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFU6omACpELO"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
      ],
      "metadata": {
        "id": "ll3f2CkhqK-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Use numpy's random number generator for reproducibility\n",
        "rng = np.random.default_rng(seed=40)\n",
        "\n",
        "# Generate 50 sample IDs\n",
        "sample_ids = [f'S{i+1}' for i in range(50)]\n",
        "\n",
        "# Generate random locations from a list\n",
        "locations = rng.choice(['Loc1', 'Loc2', 'Loc3', 'Loc4', 'Loc5'], size=50)\n",
        "\n",
        "# Generate random percentages for each element, with some missing values\n",
        "iron = rng.normal(loc=15, scale=2, size=50)\n",
        "iron[rng.choice(50, size=5, replace=False)] = np.nan  # Set 5 random values to NaN\n",
        "\n",
        "copper = rng.normal(loc=0.6, scale=0.1, size=50)\n",
        "copper[rng.choice(50, size=5, replace=False)] = np.nan\n",
        "\n",
        "nickel = rng.normal(loc=1.2, scale=0.2, size=50)\n",
        "nickel[rng.choice(50, size=5, replace=False)] = np.nan\n",
        "\n",
        "zinc = rng.normal(loc=3.3, scale=0.5, size=50)\n",
        "zinc[rng.choice(50, size=5, replace=False)] = np.nan\n",
        "\n",
        "lead = rng.normal(loc=0.12, scale=0.02, size=50)\n",
        "lead[rng.choice(50, size=5, replace=False)] = np.nan\n",
        "\n",
        "manganese = rng.normal(loc=1.6, scale=0.3, size=50)\n",
        "manganese[rng.choice(50, size=5, replace=False)] = np.nan\n",
        "\n",
        "# Create the dataframes\n",
        "df1_original = pd.DataFrame({\n",
        "    'Sample_ID': sample_ids,\n",
        "    'Location': locations,\n",
        "    'Iron (%)': iron,\n",
        "    'Copper (%)': copper,\n",
        "    'Nickel (%)': nickel,\n",
        "})\n",
        "\n",
        "df2_original = pd.DataFrame({\n",
        "    'Sample_ID': sample_ids,\n",
        "    'Zinc (%)': zinc,\n",
        "    'Lead (%)': lead,\n",
        "    'Manganese (%)': manganese,\n",
        "})"
      ],
      "metadata": {
        "id": "8d-VC7KKpNOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to deal with missing (NaN) values in both dataframes. You could fill these missing values with the mean of the respective column, or you might choose to remove the rows with missing values."
      ],
      "metadata": {
        "id": "iK4Ns_ZPpJO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill na values with the mean of that column\n",
        "\n",
        "df1 = df1_original.fillna(df1_original.mean())\n",
        "\n",
        "df2 = df2_original.fillna(df2_original.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ytQWBXVqa-I",
        "outputId": "82177b7d-71ce-4dc3-efad-ac5602ab927b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1791385228e6>:3: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df1 = df1_original.fillna(df1_original.mean())\n",
            "<ipython-input-3-1791385228e6>:5: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df2 = df2_original.fillna(df2_original.mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1_original.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTwWQV7RsL6P",
        "outputId": "c00c7cd0-cb59-4d38-b1e3-e4898193e008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample_ID     0\n",
            "Location      0\n",
            "Iron (%)      5\n",
            "Copper (%)    5\n",
            "Nickel (%)    5\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2_original.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzx4oGAFsRf7",
        "outputId": "76d4769b-aa2a-4818-e97b-6a0f65535e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample_ID        0\n",
            "Zinc (%)         5\n",
            "Lead (%)         5\n",
            "Manganese (%)    5\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove all rows with nan values:\n",
        "\n",
        "df1 = df1_original.dropna()\n",
        "df2 = df2_original.dropna()"
      ],
      "metadata": {
        "id": "8cmllvaArxfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIphFhOCrjPa",
        "outputId": "9fbe1306-5951-4375-e616-3b4a46609307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)\n",
            "0        S1     Loc3  13.979613    0.656199    1.477737\n",
            "3        S4     Loc4  18.043850    0.686388    0.976328\n",
            "4        S5     Loc3  14.621640    0.583458    1.241729\n",
            "5        S6     Loc5  13.806714    0.788045    1.024465\n",
            "6        S7     Loc1  15.483000    0.504096    1.398275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to merge these two dataframes based on the 'Sample_ID' column. This is analogous to joining two tables in SQL based on a common column."
      ],
      "metadata": {
        "id": "S8K0VrqGqbZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.merge(df1, df2, on='Sample_ID', how='inner')\n",
        "print(new_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StuCe3Exqc2l",
        "outputId": "840bc477-3c90-4592-9328-8ad1e75e4730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)  Zinc (%)  Lead (%)  \\\n",
            "0        S1     Loc3  13.979613    0.656199    1.477737  2.876792  0.091091   \n",
            "1        S6     Loc5  13.806714    0.788045    1.024465  4.165554  0.093169   \n",
            "2        S8     Loc1  16.444510    0.586295    1.111599  3.426380  0.109015   \n",
            "3        S9     Loc3  12.743632    0.729768    1.137462  3.680969  0.139411   \n",
            "4       S11     Loc1  14.458730    0.649047    1.075558  2.873618  0.096085   \n",
            "\n",
            "   Manganese (%)  \n",
            "0       1.609481  \n",
            "1       1.665416  \n",
            "2       1.679346  \n",
            "3       1.492307  \n",
            "4       1.557741  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume that there's a 'totals' field in each dataframe, representing the total percentage of all metals in a sample. Write a function to validate these 'totals' fields. If they're incorrect, generate correct 'totals' fields."
      ],
      "metadata": {
        "id": "owVLqgg8qdQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate incorrect dummy Totals:"
      ],
      "metadata": {
        "id": "BqlCicuPveUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['totals'] = np.random.randint(50, 100, size=len(new_df))"
      ],
      "metadata": {
        "id": "lPjA16MivhPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_totals = new_df[['Iron (%)', 'Copper (%)', 'Nickel (%)', 'Zinc (%)', 'Lead (%)', 'Manganese (%)']].sum(axis=1)\n",
        "incorrect_totals = new_df['totals'] != correct_totals"
      ],
      "metadata": {
        "id": "AlYJDB2xqehc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[\"totals\"] = correct_totals\n",
        "print(new_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh587jcqv6k3",
        "outputId": "a128e95c-5b63-4475-c947-de7b7e52cd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)  Zinc (%)  Lead (%)  \\\n",
            "0        S1     Loc3  13.979613    0.656199    1.477737  2.876792  0.091091   \n",
            "1        S6     Loc5  13.806714    0.788045    1.024465  4.165554  0.093169   \n",
            "2        S8     Loc1  16.444510    0.586295    1.111599  3.426380  0.109015   \n",
            "3        S9     Loc3  12.743632    0.729768    1.137462  3.680969  0.139411   \n",
            "4       S11     Loc1  14.458730    0.649047    1.075558  2.873618  0.096085   \n",
            "\n",
            "   Manganese (%)     totals  \n",
            "0       1.609481  20.690912  \n",
            "1       1.665416  21.543362  \n",
            "2       1.679346  23.357145  \n",
            "3       1.492307  19.923550  \n",
            "4       1.557741  20.710779  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, imagine you discover that the 'totals' field is off by a constant factor in one of the dataframes (say, all totals in df1 are 1.1 times what they should be). Write a function to correct this."
      ],
      "metadata": {
        "id": "P9g4fwixqenH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['totals'] = new_df['totals'] / 1.1 #change all values in the totals column by a factor of 1.1 to adjust\n",
        "print(new_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_H6edmdqf_i",
        "outputId": "05f7e231-712d-4735-db9a-d266dc5d6085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)  Zinc (%)  Lead (%)  \\\n",
            "0        S1     Loc3  13.979613    0.656199    1.477737  2.876792  0.091091   \n",
            "1        S6     Loc5  13.806714    0.788045    1.024465  4.165554  0.093169   \n",
            "2        S8     Loc1  16.444510    0.586295    1.111599  3.426380  0.109015   \n",
            "3        S9     Loc3  12.743632    0.729768    1.137462  3.680969  0.139411   \n",
            "4       S11     Loc1  14.458730    0.649047    1.075558  2.873618  0.096085   \n",
            "\n",
            "   Manganese (%)     totals  \n",
            "0       1.609481  18.809920  \n",
            "1       1.665416  19.584874  \n",
            "2       1.679346  21.233768  \n",
            "3       1.492307  18.112319  \n",
            "4       1.557741  18.827981  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, write a function to filter the samples based on their geochemical composition. For example, you might want to find all samples with above-average copper content."
      ],
      "metadata": {
        "id": "NhqWiwZ8pJR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_copper = new_df[\"Copper (%)\"].mean()\n",
        "\n",
        "good_copper = new_df[new_df[\"Copper (%)\"] > avg_copper]\n",
        "print(avg_copper)\n",
        "print(good_copper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmWazUyoqioJ",
        "outputId": "5f1dbdcd-9bc4-4e8d-a2ad-c3f7de7b2fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6428000683012032\n",
            "   Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)  Zinc (%)  Lead (%)  \\\n",
            "0         S1     Loc3  13.979613    0.656199    1.477737  2.876792  0.091091   \n",
            "1         S6     Loc5  13.806714    0.788045    1.024465  4.165554  0.093169   \n",
            "3         S9     Loc3  12.743632    0.729768    1.137462  3.680969  0.139411   \n",
            "4        S11     Loc1  14.458730    0.649047    1.075558  2.873618  0.096085   \n",
            "6        S15     Loc1  15.657167    0.653410    1.021484  3.653376  0.110419   \n",
            "10       S20     Loc4  16.381145    0.702656    0.993825  3.991522  0.074090   \n",
            "13       S25     Loc2  16.637102    0.793639    0.885401  3.162236  0.082686   \n",
            "15       S28     Loc1  15.170689    0.682830    1.242954  3.201016  0.142208   \n",
            "17       S33     Loc4  16.807258    0.666513    1.195370  3.918791  0.116463   \n",
            "21       S43     Loc3  16.730327    0.817669    1.297245  3.409289  0.125250   \n",
            "22       S45     Loc3  15.331768    0.737098    1.314433  2.225843  0.098195   \n",
            "23       S47     Loc3  15.566207    0.753454    1.441126  3.591486  0.115528   \n",
            "24       S48     Loc3  11.491305    0.720342    1.083892  4.130329  0.088791   \n",
            "26       S50     Loc2  11.579686    0.766923    0.748791  4.242912  0.123934   \n",
            "\n",
            "    Manganese (%)     totals  \n",
            "0        1.609481  18.809920  \n",
            "1        1.665416  19.584874  \n",
            "3        1.492307  18.112319  \n",
            "4        1.557741  18.827981  \n",
            "6        1.513842  20.554271  \n",
            "10       1.284691  21.298117  \n",
            "13       1.173624  20.667898  \n",
            "15       1.402050  19.856134  \n",
            "17       1.341437  21.859848  \n",
            "21       1.167224  21.406367  \n",
            "22       1.710116  19.470412  \n",
            "23       1.824236  21.174579  \n",
            "24       1.120420  16.940980  \n",
            "26       1.438665  17.182646  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort by copper in the top 10th percentile of all samples:"
      ],
      "metadata": {
        "id": "tJjxGwnLxFvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copper_threshold = new_df['Copper (%)'].quantile(0.9)\n",
        "high_copper = new_df[new_df['Copper (%)'] >= copper_threshold]\n",
        "print(copper_threshold)\n",
        "print(high_copper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25HzL9DFxCcN",
        "outputId": "0955a7d7-bb70-4b47-9230-2f6a5204a2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7753714478963861\n",
            "   Sample_ID Location   Iron (%)  Copper (%)  Nickel (%)  Zinc (%)  Lead (%)  \\\n",
            "1         S6     Loc5  13.806714    0.788045    1.024465  4.165554  0.093169   \n",
            "13       S25     Loc2  16.637102    0.793639    0.885401  3.162236  0.082686   \n",
            "21       S43     Loc3  16.730327    0.817669    1.297245  3.409289  0.125250   \n",
            "\n",
            "    Manganese (%)     totals  \n",
            "1        1.665416  19.584874  \n",
            "13       1.173624  20.667898  \n",
            "21       1.167224  21.406367  \n"
          ]
        }
      ]
    }
  ]
}